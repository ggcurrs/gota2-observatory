{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "# **この Notebook は、[Google Colab: PDF to CSV 変換器を Colab に設置 \\[第二話 死闘篇\\]  – NaN は dtype: float で捕捉！）](https://ggcs.io/2020/08/11/google-colab-pdf-export-02/)の手順詳細版です。**\n",
    "\n",
    "- Website: ごたごた気流調査所  https://ggcs.io\n",
    "- GitHub : Gota Gota Current Survey  https://github.com/ggcurrs\n",
    "- Version 1.2.0\n",
    "- Date   : 2020-08-11\n",
    "- Updated: 2020-08-17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "# 作業準備\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "- 前提1: tabula-py が Google Drive の ~/My Drive/Colab Notebooks/my-modules にインストールされていること。\n",
    "- 前提2: 読み込み元の PDF が、Google Drive の ~/My Drive/pdf_project/data/2018_co_list_jp_r.pdf に置かれていること。\n",
    "もし上記の前提が満たされていないようでしたら、[Google Colab: PDF to CSV 変換器を Colab に設置 \\[第一話 立志篇\\] – これでコピペ作業 から開放！](https://ggcs.io/2020/08/05/google-colab-pdf-export-01/)を参照の上、準備を整えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "foobar",
    "outputId": "foobar"
   },
   "outputs": [],
   "source": [
    "# Google Drive のマウント。\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Modules の import.\n",
    "import os\n",
    "import sys\n",
    "# PATH を通す（Python に modules の場所を教える）\n",
    "MODULE_PATH = '/content/drive/My Drive/Colab Notebooks/my-modules'\n",
    "sys.path.append(MODULE_PATH)\n",
    "import tabula  # Module の場所を教えたので、import.\n",
    "import pandas as pd  # 念のため明示的に import しておく。\n",
    "\n",
    "\n",
    "# ディレクトリ構造を定義する。\n",
    "PROJECT_ROOT_PATH = '/content/drive/My Drive/pdf_project'\n",
    "DATA_PATH   = os.path.join(PROJECT_ROOT_PATH, 'data')\n",
    "OUTPUT_PATH = os.path.join(PROJECT_ROOT_PATH, 'output')\n",
    "\n",
    "print('準備完了 🍻')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "# PDF ファイルの読み込み (Load a PDF File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# PDF ファイルの読み込み（30 秒程度掛かります）\n",
    "# WARNING が出ますが、今回の目的との関係では無視して差し支えありません。\n",
    "df_list = tabula.read_pdf(os.path.join(DATA_PATH, '2018_co_list_jp_r.pdf'), pages='5-112')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "## **現状確認**\n",
    "本番作業は Column > Rows の順番で行いますが、作業の都合上、DataFrame （以下「DF」）の shape を先に確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "### DataFrame Shape の確認\n",
    "- tabula で読み込んだ PDF ファイルには、PDF のページで p.5 から p.112 までの合計 108 pages 分の DF がリストの形で格納されています。\n",
    "- ここで、それぞれの DF の shape （row \\* columns）を確認してみます（TABLE 1）。\n",
    "1. すべての DF が 6 columns なので、これは吉報。項目列に大きな問題はなさそうです。\n",
    "2. ほとんどの DF が 48 rows（p.112 (6, 6) は最後の表だから 6 rows で OK）で、オリジナル PDF と比較してもそうなっているのでこれも良し 👍\n",
    "3. しかし、たとえば p.012 (111, 6) （= df_list[7]）などの raw 数は明らかにおかしい😱\n",
    "  - のでオリジナル PDF と比較するなどして確認すると…。\n",
    "  - これはマズイ。恐らくおおもとの原稿となった Excel でセル内改行（Option+改行）が行われていたため、本来は 1 row と解釈すべきところ、tabula が 3 rows と解釈してしまった模様。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# TABLE 1: Shape of DFs\n",
    "for i, each_df in enumerate(df_list):\n",
    "  if i % 5 == 0:\n",
    "    print()\n",
    "  print('p.'+str(i+5).zfill(3), each_df.shape, ' ', end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "### Column Names の確認\n",
    "- 次のスクリプトを走らせて 108 \b個の DF の 表頭（Microsoft Word でいうところの「タイトル行」）を確認すると以下のことがわかります（TABLE 2）。\n",
    "1. 異なる表頭（column names）が混在している。これは後で DF を 1 個にまとめる（concatenate）ときに悲劇を招く原因となる（オリジナル PDF の column names は揃っていたのだが tabula 読込 / parse 時に乱れてしまった ）。\n",
    "2. Column name に全角文字やスペース、改行文字（\\r）などが含まれている。作業の都合から言うと、これを放置しておくとあとあと悩みのタネになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# TABLE 2: Column Names of the DFs\n",
    "# オリジナルの Column names 確認\n",
    "column_names = [each_df.columns for each_df in df_list]\n",
    "column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "## 方針"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "### Column 関係\n",
    "- 今後のこと（Pandas や database で取り扱うこと）を考えると、今のうちに column names は以下のルールで付け替えておいた方が無難です。\n",
    "  - 半角英数字（acsii 文字）のみ使用\n",
    "  - space やヒトクセありそうな記号類は使わない\n",
    "  - 英字は原則として小文字とする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "### Row 関係\n",
    "  - 問題が起きているところは概ね、3 行で 1 組（triad）になっている印象（TABLE 3）。\n",
    "  - たとえば、index =  [6, 7, 8] の triad を例に見ると、\n",
    "row 7 の column 0 （'州' ただし次 step で 'state_code' に rename）には value ('DL') が入っているが、その上下の row 6  と row 8 が NaN になっている（NaN-str-NaN pattern）。\n",
    "  - 他の部分を見ても同様なので、このパターンになっている 3-rows をワンセット（triad）にして片付ければなんとかなりそう。\n",
    "  - どの column を対象に「Triad 狩り」をするかも重要。実際、column 0 を対象にした場合は OK だが、column 2 を対象に狩を行うと、無実の row （たとえば index = 12 の row など）まで捕捉して変換してしまって詰みます😱\n",
    "  - さらに、この Triad pattern が予期しない rows を捕捉していないかも確かめておく必要がある。\n",
    "  - あ！ index =  [36, 37, 38] は triad として捕捉してしまうとマズイ。このままでは bug です（が、見切り発車します 🚃）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# TABLE 3: 'TRIADs' found in DF.\n",
    "df_list[7].head(39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "## 実験 (Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "### Column Names の変更実験\n",
    "- Column names の変更の方は単純な話なので、こちらを先に片付けることにします（結果 > TABLE 4）。\n",
    "- 名前の対応は、\n",
    "  - 州: state_code\n",
    "  - 拠点地名: location\n",
    "  - 番号: sc_num\n",
    "  - インド進出企業名: 'com_in'\n",
    "  - 親会社名: com_jp\n",
    "  - 業種: biz_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# オリジナルの DF に影響を与えないよう、念のためコピーに対して操作\n",
    "test_df_list = df_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# 新しい column names の定義\n",
    "new_column_names = ['state_code', 'location', 'sc_num', 'com_in', 'com_jp', 'biz_type']\n",
    "# 108 個の DataFrame の column name を統一する。\n",
    "for each_df in test_df_list:\n",
    "  each_df.columns = new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# TABLE 4: Renamed Columns\n",
    "# 変換後の Column names 確認\n",
    "for each_df in test_df_list:\n",
    "  print(each_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "### Non-48-row-DF の整形実験\n",
    "1. 整形操作概要\n",
    "- 上記の「現状確認」を眺めてみると、columns 3, 4, 5 のそれぞれについて、NaN-str-NaN パターンの 3 rows を 1 row にまとめ、かつ、文字列 'nan' が入らないようにすればよさそう。方法としては;\n",
    "  - Method A: リスト内包表記を使う方法;\n",
    "  - Method B: Filter を使う方法 1;\n",
    "  - Method C: Filter を使う方法 2\n",
    "\n",
    "  で試してみる。\n",
    "2. 結果を見ると、いずれの Method でも得られる結果に違いはありませんが、別途測定したところ Method A（リスト内包表記）の処理速度が若干早かったので、本番では Method A を使うことにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# Methods A, B and C を試してみる。\n",
    "def akb_48_test(bad_df):\n",
    "  '''Search for the NaN-str-NaN pattern in the column 2, \n",
    "     educate and transform non_48 DataFrames to akb_48 DataFrames'''\n",
    "  bad_df.reset_index()  # Preparation / 念のため\n",
    "  for i in range(1, len(bad_df) - 1):\n",
    "    # Find NaN-str-NaN (float-str-float) patterns ('triad' streaches)\n",
    "    # in the column 2.\n",
    "    if (\n",
    "        (type(bad_df.iat[i-1, 0]) == float) &\n",
    "        (type(bad_df.iat[i  , 0]) == str) &\n",
    "        (type(bad_df.iat[i+1, 0]) == float)):\n",
    "      # Target cells in the columns 3, 4, and 5.\n",
    "      clm_3_triad = [bad_df.iat[i-1, 3], bad_df.iat[i, 3], bad_df.iat[i+1, 3]]\n",
    "      clm_4_triad = [bad_df.iat[i-1, 4], bad_df.iat[i, 4], bad_df.iat[i+1, 4]]\n",
    "      clm_5_triad = [bad_df.iat[i-1, 5], bad_df.iat[i, 5], bad_df.iat[i+1, 5]]\n",
    "\n",
    "      # clm は修正前、new は修正したもの。並べて比較\n",
    "      print('\\nIndex', str(i).zfill(3), '± 1',\n",
    "            \n",
    "            '\\nclm_3_triad', clm_3_triad,  # Method A (List comprehension)\n",
    "            '\\nnew_3_triad', [x for x in clm_3_triad if not type(x) == float],\n",
    "\n",
    "            '\\n\\nclm_4_triad', clm_4_triad,  # Method B (Filter/lambda)\n",
    "            '\\nnew_4_triad', list(filter(lambda x: not type(x) == float, \n",
    "                                         clm_4_triad)), \n",
    "\n",
    "            '\\n\\nclm_5_triad', clm_5_triad,  # Method C (Filter/lambda)\n",
    "            '\\nnew_5_triad', list(filter(lambda x: x if not type(x) == float \n",
    "                                         else None, clm_5_triad)),'\\n'\n",
    "            )\n",
    "      \n",
    "\n",
    "if __name__ == '__main__':\n",
    "  akb_48_test(test_df_list[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "## 本番"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "### Column Names の変更\n",
    "- 上記の「実験」で行なったのと全く同じ操作を本番用 DF 全体（108 個）に対して行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# Rename columns.\n",
    "new_column_names = ['state_code', 'location', 'sc_num', 'com_in', 'com_jp', 'biz_type']\n",
    "# 108 個の DataFrame の column name を統一する。\n",
    "for each_df in df_list:\n",
    "  each_df.columns = new_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "### Non-48-row-DF の整形\n",
    "- 108 個の DF のうち、ほとんど（104 個）は 48 rows \\* 6 columns (最後の DF は 6 rows \\* 6 columns）なので、下手に整形操作を加えて壊しちゃうと嫌過ぎる。\n",
    "- そこで、問題のある 4 個の DF を含んだリストを隔離（list_df_non_48）し、これに対してだけ修正操作を行うことにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# Isolate non_48-row type DFs as df_non_48.\n",
    "list_df_non_48 = [each_df for each_df in df_list if len(each_df) > 48]\n",
    "list_df_48     = [each_df for each_df in df_list if len(each_df) <= 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "def akb_48(bad_df):\n",
    "  '''Educate and transform non_48 DataFrames to akb_48 DataFrames'''\n",
    "  # Create 'good_df' for output.\n",
    "  good_df = bad_df.copy()\n",
    "  bad_df.reset_index()  # Preparation / 念のため\n",
    "  for i in range(1, len(bad_df) - 1):\n",
    "    # Find NaN-str-NaN (float-str-float) patterns ('triad' streaches)\n",
    "    # in the column 0.\n",
    "    if (\n",
    "        (type(bad_df.iat[i-1, 0]) == float) &\n",
    "        (type(bad_df.iat[i  , 0]) == str) &\n",
    "        (type(bad_df.iat[i+1, 0]) == float)):\n",
    "      # Target triads in the columns (clm) 3, 4, and 5\n",
    "      clm_3_triad = [bad_df.iat[i-1, 3], bad_df.iat[i, 3], bad_df.iat[i+1, 3]]\n",
    "      clm_4_triad = [bad_df.iat[i-1, 4], bad_df.iat[i, 4], bad_df.iat[i+1, 4]]\n",
    "      clm_5_triad = [bad_df.iat[i-1, 5], bad_df.iat[i, 5], bad_df.iat[i+1, 5]]\n",
    "      # Merge each triad into one, remove NaN (NaN: dtype = float).\n",
    "      new_clm_3 = ', '.join([x for x in clm_3_triad if not type(x) == float])\n",
    "      new_clm_4 = ', '.join([x for x in clm_4_triad if not type(x) == float])\n",
    "      new_clm_5 = ', '.join([x for x in clm_5_triad if not type(x) == float])\n",
    "      # Refresh the columns 3, 4, 5 of the good_df (output DF).\n",
    "      good_df.iat[i, 3] = new_clm_3\n",
    "      good_df.iat[i, 4] = new_clm_4\n",
    "      good_df.iat[i, 5] = new_clm_5\n",
    "\n",
    "  # Drop gargabe rows\n",
    "  good_df.dropna(subset= ['sc_num'], inplace=True)\n",
    "  # After dropping rows, reset the index!\n",
    "  good_df.reset_index(drop=True, inplace=True)\n",
    "  \n",
    "  return good_df\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # Create an empty list.\n",
    "  list_df_yes_48 = []\n",
    "  # Cleansing\n",
    "  for bad_df in list_df_non_48:\n",
    "    good_df = akb_48(bad_df)\n",
    "    list_df_yes_48.append(good_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "### 結果確認\n",
    "- ぱっと見は良い（概ねうまくいった）のだけど、\n",
    "- 以下の rows に問題がある。 > 最後に目視確認して手作業で修正した方が早いので、そのようにする方針（敗北感…😭）。\n",
    "1. list_df_new[0]\n",
    "  - 13\tHR\tBawal\t7\n",
    "  - 18\tHR\tBawal\t12\n",
    "  - 32\tHR\tBawal\t26\n",
    "  - 34\tHR\tBawal\t28\n",
    "  - 41\tHR\tDharuhera\t35\n",
    "2. list_df_new[1]\n",
    "  - 24\tMH\tMumbai\t273\n",
    "3. list_df_new[2]\n",
    "  - 14\tTN\tChennai\t176\n",
    "  - 35\tTN\tChennai\t197\n",
    "4. list_df_new[3]\n",
    "  - 15\tTN\tChennai\t225\n",
    "  - 24\tTN\tChennai\t234\n",
    "  - 26\tTN\tChennai\t236\n",
    "  - 29\tTN\tChennai\t239\n",
    "  - 36\tTN\tChennai\t246\n",
    "  - 37\tTN\tChennai\t247\n",
    "  - 38\tTN\tChennai\t248\n",
    "  - 47\tTN\tChennai\t257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# Check the results.\n",
    "list_df_yes_48[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# Check the results.\n",
    "list_df_yes_48[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# Check the results.\n",
    "list_df_yes_48[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# Check the results.\n",
    "list_df_yes_48[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "## DF List > Single DF\n",
    "- まだ問題が残っていることを重々承知の上で、これを放置して次に進みます（👈急いては事を仕損じるタイプ）。\n",
    "1. df_non_48 を修正した list_df_yes_48 と、取り分けて温存しておいた df_48 とを合体して復元。\n",
    "2. 復元した df_list_tmp の中身（108 個の DF）を 1 本の単独 DF に concatenate する（つなげる）。\n",
    "3. これまでの操作を加えた後で 'state_code' が NaN の row は row ごと drop しても大丈夫なので、dropna しておく。\n",
    "4. Row を drop したあとは reset_index() して気分一新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# 1. Reconstruct the DF list.\n",
    "df_list_tmp = list_df_yes_48 + list_df_48 \n",
    "# 2. Concatenate 108 DFs to produce intermediate DF.\n",
    "df_all_intermed = pd.concat(df_list_tmp)\n",
    "# 3. Remove garvage rows.\n",
    "df_all_intermed.dropna(subset = ['state_code'], inplace=True)\n",
    "# 4. Reset the index of the DF.\n",
    "df_all_intermed.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "# 中間レビュー Review\n",
    "- 中間産物の describe() を取って、仕上がり具合を確認します（TABLE 5）。\n",
    "1. オリジナル PDF の表は複数\bページに分かれており、それぞれに表頭が付いています（Microsoft Word でいうと「タイトル行の繰り返し」状態）。このため、df_all_intermed には余分の表頭が含まれています。\n",
    "  - その結果、例えば、TABLE 5 で state_code （基礎知識: インドの州の略記。英字 2 文字。本資料作成時点で 33 種類）の unique が 70 （本来なら 33 のはず）となっているのは、state_code のところに表頭の文字列が入ってしまっているためと推測されます（head() method などを使って簡単に確認できます）。\n",
    "2. com_in （現地拠点）の count が 5106 となっているのは良い知らせです（オリジナル PDF の最初に書いてあるように、日系企業の調査時点における現地拠点数は 5102 か所です）。\n",
    "3. 'sc_num' column（州ごとに振ってある拠点番号。当然 integer でなければならない）が decimal ぽく表示されていますが、DF を直接確認したら、ちゃんと int 型になっていたので大丈夫😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "foobar",
    "outputId": "foobar"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>location</th>\n",
       "      <th>sc_num</th>\n",
       "      <th>com_in</th>\n",
       "      <th>com_jp</th>\n",
       "      <th>biz_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5142</td>\n",
       "      <td>5108</td>\n",
       "      <td>5106.0</td>\n",
       "      <td>5106</td>\n",
       "      <td>4942</td>\n",
       "      <td>5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>70</td>\n",
       "      <td>737</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1723</td>\n",
       "      <td>1100</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MH</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Reliance Nippon Life Insurance Company</td>\n",
       "      <td>日本生命保険</td>\n",
       "      <td>26 金融業、保険業/  Finance and insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>810</td>\n",
       "      <td>456</td>\n",
       "      <td>27.0</td>\n",
       "      <td>628</td>\n",
       "      <td>629</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       state_code  location  ...  com_jp                            biz_type\n",
       "count        5142      5108  ...    4942                                5106\n",
       "unique         70       737  ...    1100                                  57\n",
       "top            MH  Gurugram  ...  日本生命保険  26 金融業、保険業/  Finance and insurance\n",
       "freq          810       456  ...     629                                1419\n",
       "\n",
       "[4 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TABLE 5: Description of the intermediate DF\n",
    "df_all_intermed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "- 'state_code' column に 英字2文字の state code 以外のものが入ってる rows は簡単に drop することができるので、いまは Review 中ですがちょっと作業をして、サクッと drop しておくことにします（👈計画性の欠如）。\n",
    "- 結果（TABLE 6）を見ると、'state_code' の unique もちゃんと 33 になったし、\n",
    "- 他の columns も概ね 5102（資料作成時点の現地拠点数）と一致しており、ゴールは近い！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "for i in range(len(df_all_intermed) - 1):\n",
    "  if not len(df_all_intermed.at[i, 'state_code']) == 2:\n",
    "    df_all_intermed.drop(i, inplace=True)\n",
    "# Don't forget to reset the index.\n",
    "df_all_intermed.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "foobar",
    "outputId": "foobar"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>location</th>\n",
       "      <th>sc_num</th>\n",
       "      <th>com_in</th>\n",
       "      <th>com_jp</th>\n",
       "      <th>biz_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5102</td>\n",
       "      <td>5102</td>\n",
       "      <td>5102.0</td>\n",
       "      <td>5102</td>\n",
       "      <td>4938</td>\n",
       "      <td>5102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>33</td>\n",
       "      <td>734</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>1722</td>\n",
       "      <td>1099</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MH</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Reliance Nippon Life Insurance Company</td>\n",
       "      <td>日本生命保険</td>\n",
       "      <td>26 金融業、保険業/  Finance and insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>810</td>\n",
       "      <td>456</td>\n",
       "      <td>27.0</td>\n",
       "      <td>628</td>\n",
       "      <td>629</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       state_code  location  ...  com_jp                            biz_type\n",
       "count        5102      5102  ...    4938                                5102\n",
       "unique         33       734  ...    1099                                  56\n",
       "top            MH  Gurugram  ...  日本生命保険  26 金融業、保険業/  Finance and insurance\n",
       "freq          810       456  ...     629                                1419\n",
       "\n",
       "[4 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TABLE 6: Description of the intermediate DF\n",
    "df_all_intermed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "# ☕︎ここで休憩\n",
    "- ここまでの作業結果を、CSV に保存します（Google Drive に作った data フォルダの中に 'df_all_intermed.csv'という 名前で保管します。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# 以下で説明する問題が発覚したため、いったんコメントアウトします。\n",
    "#df_all_intermed.to_csv(os.path.join(DATA_PATH, 'df_all_intermed.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "## 重大事実の発覚😱\n",
    "- Google Drive から df_all_intermed.csv を local に落として、適当なソフトで開いてみると…。\n",
    "  - イイね、イイね、完璧じゃん、ほぼ出来上がり😸\n",
    "  - …と思いきや、途中から変なところで row が折り返され、shape がメチャメチャになってしまう事案が多発？なんなの、コレ？😱\n",
    "  - こりゃ何か変な事をやらかしちゃったかな？と、script 修正を数回試みるも症状は変わらず😭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "## 原因及び対策\n",
    "- \b\b\b\bしばし茫然自失としていたら、どこからか神様の声が…。\n",
    "- 「r だよ、r. \\r, r’\\r’, CR !」\n",
    "- ああ、思い出した。自分でも「Column Names の確認」のところで、「Column name に全角文字やスペース、改行文字（\\r）などが含まれている。」って書いてるじゃん？\n",
    "- そこで問題の箇所を確認すると、原稿の Excel で「セル内改行」が行われていたとおぼしきところに \\r が挿入されていました。\n",
    "- というわけで、やり直し。改行文字（\\r）を差し障りのなさそうな文字列 '\\<br\\>'\b に replace してから保存することにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "# regex で \\r を <br> に replace\n",
    "df_all_intermed.replace(r'\\r', r'<br>', inplace=True, regex=True)\n",
    "# CSV に保存\n",
    "df_all_intermed.to_csv(os.path.join(DATA_PATH, 'df_all_intermed.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "## Excel で保存したら大丈夫だった\n",
    "- もしかしたら、と思って、CSV じゃなくて Excel なら Microsoft 同士だから忖度してくれるんじゃないか、と思って、\r を <br> に replace する前の DF で試したみたところ、\n",
    "- 予想に違わず、\\r が混入した DF も何の問題もなく期待した形式の表として Excel Book に保存できました（ヤレヤレ…）。\n",
    "- （追記）が、このファイルには依然として地雷が埋まっているわけですから、実際には使わないことにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foobar"
   },
   "outputs": [],
   "source": [
    "#df_all_intermed.to_excel(os.path.join(DATA_PATH, 'df_all_intermed.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foobar"
   },
   "source": [
    "# 次回計画\n",
    "1. 宿題（cf.「結果確認」）\bを片付ける。それから、CSV におとしたら 'sc_num' はやはり decimal っぽくなっていたのでこれも直す。\n",
    "2. 'biz-type' の正規化。現状で unique 値が 56 個ですが、これは本当の数の倍ぐらいに増えちゃっています（triad 退治などの影響）\n",
    "3. 表全体の目視確認\n",
    "4. 正規化: 'com_in', 'com_jp', 'biz_type' は別の table に分けて foreigh key で引っ張ってくるようにした方が良さそう（言うのは簡単）。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pdf_to_csv_prep.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
