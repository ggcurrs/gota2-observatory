#!/usr/bin/env python
# coding: utf-8
__author__ = "Admin GGCS"
__copyright__ = "Copyright 2020"
__license__ = "MIT"
__version__ = "1.1.1"
__maintainer__ = "Admin GGCS"
__website__ = "ggcs.io"

# Updated on 2020-08-01

# BBS Threads to CSV
'''æŸæ²ç¤ºæ¿ã‚¹ãƒ¬ãƒƒãƒ‰ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å†…å®¹ã‚’æ•´ç†ã—ã¦CSVãƒ•ã‚¡ã‚£ãƒ«ã«æ›¸ãå‡ºã™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ'''

## ä»Šå›ä½¿ã†ã‚‚ã®
import os
import sys
import chardet # Added on 2020-08-01
from bs4 import BeautifulSoup
import re
import pandas as pd

'''## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®šã€‚æ•´ç†æ•´é “ğŸ˜‰
1. Projectãƒ•ã‚©ãƒ«ãƒ€ï¼ˆPROJECT_ROOT_PATHï¼‰ã‚’èã‹ã‚Œã‚‹ã®ã§ã€ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã™ã‚‹ã€‚Current Directoryã§è‰¯ã„ãªã‚‰ "." ã‚’å…¥åŠ›ã™ã‚Œã°OKã€‚
2. Projectãƒ•ã‚©ãƒ«ãƒ€ã®ä¸‹ã« "source" ã¨ã„ã†ãƒ•ã‚©ãƒ«ãƒ€ãŒã§ãã‚‹ã®ã§ã€åˆ†æã—ãŸã„HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¨éƒ¨ã“ã“ã«å…¥ã‚Œã¦ãŠãï¼ˆãã‚Œä»¥å¤–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç½®ã„ã¡ã‚ƒãƒ€ãƒ¡ï¼‰ã€‚
3. Projectãƒ•ã‚©ãƒ«ãƒ€ã®ä¸‹ã« "output"ã¨ã„ã†ãƒ•ã‚©ãƒ«ãƒ€ãŒã¤ãã‚Œã‚‹ã€‚å‡ºæ¥ä¸ŠãŒã‚Šã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã¯ã“ã“ã«è“„ç©ã•ã‚Œã‚‹ã€‚
'''

# Directory set up
my_project_root_path = input('PROJECT_ROOT_PATH = ? >>  ')

PROJECT_ROOT_PATH = my_project_root_path
SOURCE_PATH = os.path.join(PROJECT_ROOT_PATH, 'source')
OUTPUT_PATH = os.path.join(PROJECT_ROOT_PATH, 'output')

if not os.path.isdir(SOURCE_PATH):
    os.makedirs(SOURCE_PATH)
if not os.path.isdir(OUTPUT_PATH):
    os.makedirs(OUTPUT_PATH)

# Confirmation:
print('Project Root path: ', PROJECT_ROOT_PATH)
print('Source path      : ', SOURCE_PATH)
print('Output Path      : ', OUTPUT_PATH)



"""## æœ¬ä½“éƒ¨åˆ†
1. å¯¾è±¡ã¨ãªã‚‹HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®ç½®ãå ´æ‰€ï¼ˆtarget_html_pathï¼‰ã‚’ä¸ãˆã‚‹ã¨ã€CSVãƒ•ã‚¡ã‚£ãƒ«ã«æ•´ç†ã—ã¦ã€
2. output ãƒ•ã‚©ãƒ«ãƒ€ã«æ›¸ãå‡ºã™ã€‚
"""

# Preparation:
print('\n*** HTMLãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™çŠ¶æ³ã®ç¢ºèª ***')
prep = input('HTMLãƒ•ã‚¡ã‚¤ãƒ«ã¯sourceãƒ•ã‚©ãƒ«ãƒ€ã«æº–å‚™ã•ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ[Y]/N) >>  ').lower()
if not (prep == 'n' or prep == 'no'):
  source_list = os.listdir(SOURCE_PATH) # Your source files have been listed.
else:
  sys.exit('*** Aborted ***')

# Set HTML encoding.
## æŸæ²ç¤ºæ¿ã®å ´åˆã€chardet ã ã¨æ­£è§£ã®ç¢ºç‡ãŒä½ã„ã®ã§ã€ãŠæ‰‹æ•°ã§ã™ãŒæ‰‹å‹•ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚
print('\n*** Encodingã®ç¢ºèª ***')
print('''HTML ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã€
  1: ã¨ã€ã‚ã‚‹æ–¹æ³•ã§ç”¨æ„ã—ãŸå ´åˆã¯1ã‚’é¸æŠ;
  2: ãƒ–ãƒ©ã‚¦ã‚¶ã§ã€Œãƒšãƒ¼ã‚¸ã‚’ä¿å­˜ã€ã—ãŸå ´åˆã¯2ã‚’é¸æŠ;
  3: ä¸Šè¨˜ã§ãƒ€ãƒ¡ã ã£ãŸå ´åˆã¯3ã‚’é¸æŠ;
ãã‚Œã§ã‚‚ãƒ€ãƒ¡ã ã£ãŸå ´åˆã¯ã€è«¦ã‚ã¦ãã ã•ã„ ğŸ˜­
''')
my_encoding = input('''
HTML Encoding [1, 2, 3]?
  1: UTF8
  2: Shift JIS
  3: CP932\n
>> ''')

if my_encoding == '1':
    my_enc = 'utf_8'
elif my_encoding == '2':
    my_enc = 'shift_jis'
elif my_encoding == '3':
    my_enc = 'cp932'
else:
    sys.exit('Please try again')

'''
*************
  CORE PART
*************'''
def thread_to_csv(target_html_path):
  '''Convert a bbs thread to a CSV file'''
  # Version 1.0.0 ã§è€ƒæ…®ã—ã¦ã„ãªã‹ã£ãŸ encoding ã®é•ã„ã‚’å¸åã€‚
  with open(target_html_path, encoding = my_enc) as f:
    soup = BeautifulSoup(f, 'lxml')

  # Preparation:
  thread_title = soup.select('h1')[0].text
  post_list = soup.select('div.post')
  df = pd.DataFrame(columns = ['TITLE', 'POST#', 'NAME',
                               'DATE&TIME_JST', 'ID', 'MESSAGE'])
  # Extract contents from each post and clean the data:
  for i, post in enumerate(post_list):
    # Extact contents
    post_number  = post.select('span.number')[0].text # Reply Number
    post_name    = post.select('span.name')[0].text   # Name
    post_date    = post.select('span.date')[0].text   # Date and Time
    post_uid     = post.select('span.uid')[0].text    # ID
    post_message = post.select('div.message')[0].text # Message content

    # Data cleansing
    ## Format the DATE&TIME_JST strings.
    p = re.compile(r'(\d{4})/(\d{2})/(\d{2})\(.\) (\d{2}:\d{2}:\d{2}.\d{2})')
    post_date = p.sub(r'\1-\2-\3T\g<4>0', post_date)


    # Store the contents in a data frame.
    cf = pd.DataFrame([None, post_number, post_name,
                       post_date, post_uid, post_message]).T
    cf.columns = ['TITLE', 'POST#', 'NAME', 'DATE&TIME_JST', 'ID', 'MESSAGE']
    df = df.append(cf)

  # Brush up the dataframe
  df['TITLE'] = thread_title
  df.reset_index(drop=True, inplace=True)

  ## Want to drop rows where 'ID' like 'Thread'
  ### Where are they?
  #df.loc[df['ID'] == 'Thread']
  ### Their index numbers are:
  #df.loc[df['ID'] == 'Thread'].index
  ## Then drop them!
  ## Version 1.0.0 ã§ã¯ä½™è¨ˆãª 'index=' ãŒæ®‹ã£ã¦ã„ã¾ã—ãŸæ¸ˆã¿ã¾ã›ã‚“ğŸ™‡â€â™‚ï¸
  df.drop(df.loc[df['ID'] == 'Thread'].index, inplace=True)

  # Output to a CSV file.
  output_file_name = os.path.basename(target_html).replace('html', 'csv')
  output_file_path = os.path.join(OUTPUT_PATH, output_file_name)
  df.to_csv(output_file_path, index = None)

  print(output_file_name, ': DONE')

if __name__ == '__main__':
  for target_html in source_list:
    thread_to_csv(os.path.join(SOURCE_PATH, target_html))
